{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOzKboRZJe6YmZ0YI38G+mU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nobertomaciel/PLN-ANIMA/blob/main/PLN_Analise_de_sentimentos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPSPGP-0ONOm"
      },
      "outputs": [],
      "source": [
        "# ===============================================\n",
        "# Exemplo pr√°tico de Processamento de Linguagem Natural (PLN)\n",
        "# Aplica√ß√£o: An√°lise de sentimentos de avalia√ß√µes de produtos\n",
        "# T√©cnicas: Tokeniza√ß√£o, Stopwords, Bag-of-Words, TF-IDF, Word2Vec\n",
        "# ===============================================\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Baixar recursos necess√°rios do NLTK (apenas na primeira execu√ß√£o)\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# ===============================================\n",
        "# 1Ô∏è‚É£ Exemplo de dataset realista\n",
        "# ===============================================\n",
        "avaliacoes = [\n",
        "    \"O celular √© √≥timo, tem uma c√¢mera excelente!\",\n",
        "    \"Horr√≠vel! Que produto terr√≠vel, n√£o recomendo a ningu√©m.\",\n",
        "    \"Entrega r√°pida e produto de boa qualidade.\",\n",
        "    \"A bateria dura pouco e esquenta muito. P√©ssimo!\",\n",
        "    \"Muito bom, atendeu todas as minhas expectativas.\",\n",
        "]\n",
        "\n",
        "# ===============================================\n",
        "# 2Ô∏è‚É£ Fun√ß√£o de pr√©-processamento\n",
        "# ===============================================\n",
        "def preprocessar_texto(texto):\n",
        "    texto = texto.lower()                               # min√∫sculas\n",
        "    texto = re.sub(r'[^a-zA-Z√†-√∫√Ä-√ö\\s]', '', texto)     # remove pontua√ß√£o e n√∫meros\n",
        "    tokens = nltk.word_tokenize(texto, language='portuguese')  # tokeniza√ß√£o\n",
        "    stop_words = set(stopwords.words('portuguese'))\n",
        "    tokens = [t for t in tokens if t not in stop_words and len(t) > 2]  # remove stopwords\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "avaliacoes_limpo = [preprocessar_texto(a) for a in avaliacoes]\n",
        "\n",
        "print(\"üîπ Textos ap√≥s pr√©-processamento:\")\n",
        "print(avaliacoes_limpo)\n",
        "print()\n",
        "\n",
        "# ===============================================\n",
        "# 3Ô∏è‚É£ Representa√ß√£o Bag-of-Words\n",
        "# ===============================================\n",
        "bow_vectorizer = CountVectorizer()\n",
        "bow_matriz = bow_vectorizer.fit_transform(avaliacoes_limpo)\n",
        "\n",
        "print(\"üîπ Representa√ß√£o Bag-of-Words (sparse matrix):\")\n",
        "print(pd.DataFrame(bow_matriz.toarray(), columns=bow_vectorizer.get_feature_names_out()))\n",
        "print()\n",
        "\n",
        "# ===============================================\n",
        "# 4Ô∏è‚É£ Representa√ß√£o TF-IDF\n",
        "# ===============================================\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_matriz = tfidf_vectorizer.fit_transform(avaliacoes_limpo)\n",
        "\n",
        "print(\"üîπ Representa√ß√£o TF-IDF:\")\n",
        "print(pd.DataFrame(tfidf_matriz.toarray(), columns=tfidf_vectorizer.get_feature_names_out()))\n",
        "print()\n",
        "\n",
        "# ===============================================\n",
        "# 5Ô∏è‚É£ Representa√ß√£o Word2Vec\n",
        "# ===============================================\n",
        "# Para o Word2Vec, usamos listas de tokens (n√£o texto √∫nico)\n",
        "tokens_avaliacoes = [a.split() for a in avaliacoes_limpo]\n",
        "\n",
        "modelo_w2v = Word2Vec(sentences=tokens_avaliacoes, vector_size=50, window=3, min_count=1, sg=1)\n",
        "print(\"üîπ Vocabul√°rio do modelo Word2Vec:\")\n",
        "print(list(modelo_w2v.wv.index_to_key))\n",
        "print()\n",
        "\n",
        "# Exemplo: similaridade entre palavras\n",
        "print(\"üîπ Similaridade entre '√≥timo' e 'excelente':\")\n",
        "try:\n",
        "    print(modelo_w2v.wv.similarity('√≥timo', 'excelente'))\n",
        "except KeyError:\n",
        "    print(\"Alguma das palavras n√£o foi encontrada no vocabul√°rio.\")\n",
        "\n",
        "# ===============================================\n",
        "# 6Ô∏è‚É£ Aplica√ß√£o pr√°tica: vetorizar novas avalia√ß√µes\n",
        "# ===============================================\n",
        "nova_avaliacao = \"A qualidade da c√¢mera √© muito boa, mas a bateria dura pouco.\"\n",
        "nova_avaliacao_proc = preprocessar_texto(nova_avaliacao)\n",
        "nova_tfidf = tfidf_vectorizer.transform([nova_avaliacao_proc])\n",
        "\n",
        "print(\"\\nüîπ Nova avalia√ß√£o pr√©-processada:\")\n",
        "print(nova_avaliacao_proc)\n",
        "print(\"\\nüîπ Vetor TF-IDF correspondente:\")\n",
        "print(pd.DataFrame(nova_tfidf.toarray(), columns=tfidf_vectorizer.get_feature_names_out()))\n"
      ]
    }
  ]
}